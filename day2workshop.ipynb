{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e46e85d-14df-4233-b0f1-2ac821f73d76",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87443dd-fec1-4250-82a9-5ad0144a57ae",
   "metadata": {},
   "source": [
    "Typical imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d43c8b-498d-42b2-98d0-7a57636fe2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284444ab-6300-45dc-b6ad-2eb67f95da19",
   "metadata": {},
   "source": [
    "Define our Michaelis-Menten equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638bbbc-2668-4925-84b6-b3943205a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def michaelis_menten(s, km, vmax):\n",
    "    '''The Michaelis-Menton function.'''\n",
    "    s = np.array(s)\n",
    "    return (vmax*s) / (km + s)\n",
    "\n",
    "def michaelis_menten_ha(s, kd1, kd2, alpha, beta, vmax):\n",
    "    '''The Michaelis-Menton function including homotropic allosterism.'''\n",
    "    s = np.array(s)\n",
    "    numerator = vmax * (s/kd1) + (beta * vmax * (s**2)/(alpha * kd1 *kd2))\n",
    "    denominator = 1 + (s/kd1) + (s/kd2) + (s**2)/(alpha * kd1 * kd2)\n",
    "    \n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a660e7-3525-4b2d-bd7b-12bb0b442d40",
   "metadata": {},
   "source": [
    "Setup some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5640d0-e7f1-4e46-a7ce-00325b7e30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MM_VMAX = 10\n",
    "MM_KM = 0.3\n",
    "SUBSTRATE_CONCENTRATIONS = [0, 0.1, 0.3, 0.6, 1, 2]\n",
    "SMOOTH_X = np.linspace(min(SUBSTRATE_CONCENTRATIONS), max(SUBSTRATE_CONCENTRATIONS), 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93500c-5ba3-4177-b489-b43ecd922390",
   "metadata": {},
   "source": [
    "Create a dataset with a single replicate (ooh, FAKE DATA!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7083c33-b654-49b0-b5ca-2a86049d78bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_data = pd.DataFrame({'[s]': SUBSTRATE_CONCENTRATIONS,\n",
    "                        'v':           michaelis_menten(SUBSTRATE_CONCENTRATIONS, MM_KM, MM_VMAX)}\n",
    "                      )\n",
    "mm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd69192-4f9a-451b-9169-fb7be8da529e",
   "metadata": {},
   "source": [
    "... add some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df28f390-610a-4f33-88d8-326fda6e5234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noisy(y, first_no_noise=True):\n",
    "    rng = np.random.default_rng()\n",
    "    noisy = y + rng.normal(0, 0.3, len(y))\n",
    "    if first_no_noise:\n",
    "        noisy[0] = y[0]\n",
    "    return noisy\n",
    "\n",
    "mm_data['v_noisy'] = make_noisy(mm_data['v'])\n",
    "mm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a521f-6f8c-4cf4-addf-e80ead7fd1fa",
   "metadata": {},
   "source": [
    "### ALWAYS LOOK AT YOUR DATA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce599620-5364-4547-8b5e-2dde73bd7ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mm_data['[s]'],mm_data['v'], label='ground_truth', marker='x')\n",
    "plt.scatter(mm_data['[s]'],mm_data['v_noisy'], label='with noise', color='orange')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04a52a-2f2f-44de-9f3f-29fffe894d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_fitted, mm_covariance = curve_fit(f=michaelis_menten,\n",
    "                                     xdata=mm_data['[s]'],\n",
    "                                     ydata=mm_data['v_noisy'],\n",
    "                                     bounds=(0, np.inf)  # Force both Km and Vmax to be positive\n",
    "                                    )\n",
    "print('The theoretical K_m and V_max are: ', MM_KM, MM_VMAX)\n",
    "print('With my noisy data, the K_m and V_max are:', mm_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dae252-7bd5-40eb-b2a9-af70497fd3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(SMOOTH_X,\n",
    "         michaelis_menten(SMOOTH_X, MM_KM, MM_VMAX),\n",
    "         label='Ground Truth')\n",
    "plt.plot(SMOOTH_X,\n",
    "         michaelis_menten(SMOOTH_X, mm_fitted[0], mm_fitted[1]),\n",
    "         label='Fitted')\n",
    "plt.scatter(mm_data['[s]'], mm_data['v_noisy'], label='with noise', color='orange')\n",
    "\n",
    "standard_deviations = np.sqrt(np.diag(mm_covariance)) \n",
    "plus_1sd_km  = mm_fitted[0] + 1 * standard_deviations[0]\n",
    "minus_1sd_km = mm_fitted[0] - 1 * standard_deviations[0]\n",
    "plus_1sd_vmax  = mm_fitted[1] + 1 * standard_deviations[1]\n",
    "minus_1sd_vmax = mm_fitted[1] - 1 * standard_deviations[1]\n",
    "\n",
    "bound_upper = michaelis_menten(SMOOTH_X, minus_1sd_km, plus_1sd_vmax)\n",
    "bound_lower = michaelis_menten(SMOOTH_X, plus_1sd_km, minus_1sd_vmax)\n",
    "plt.fill_between(SMOOTH_X, bound_upper, bound_lower, color = 'blue', alpha = 0.1, label='Â±1SD')\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80c384-ec9c-4c51-8c0b-2f81223e76a2",
   "metadata": {},
   "source": [
    "# Bootstrap\n",
    "Here, we demonstrate The Bootstrap.  The function `one_bootstrap_fit` uses *Pandas* `.sample()` method to generate our bootstrap sample (with replacement.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118959a-9338-49cf-80f5-63225be9cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_bootstrap_fit(df):\n",
    "    sampled = df.sample(n=len(df), replace=True)\n",
    "    mm_fitted, mm_covariance = curve_fit(f=michaelis_menten,\n",
    "                                     xdata=sampled['[s]'],\n",
    "                                     ydata=sampled['v_noisy'],\n",
    "                                     bounds=(0, np.inf)  # Force both Km and Vmax to be positive\n",
    "                                    )\n",
    "    return mm_fitted\n",
    "one_bootstrap_fit(mm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60852cf-1406-4a71-affb-3cdcd07cad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_fits_100 = []\n",
    "for _ in range(100):\n",
    "    bootstrap_fits_100.append(one_bootstrap_fit(mm_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f4e9d-c29d-488a-9b25-91364ac97ec6",
   "metadata": {},
   "source": [
    "We can now plot a histogram of values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781feee-8309-4b81-9154-1e0e91d30728",
   "metadata": {},
   "outputs": [],
   "source": [
    "kms, vmaxs = [], []\n",
    "for bootstrap_fit in bootstrap_fits_100:\n",
    "    kms.append(bootstrap_fit[0])\n",
    "    vmaxs.append(bootstrap_fit[1])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "axs[0].hist(kms, bins=100)\n",
    "axs[0].set_title('$K_m$');\n",
    "axs[1].hist(vmaxs, bins=100)\n",
    "axs[1].set_title('$V_{max}$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb385ca3-b769-4966-abf6-eedfdf406091",
   "metadata": {},
   "source": [
    "... And zoom-in to look at any low-occurance samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58149f-5556-49ae-8233-c79e35d71dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "axs[0].hist(kms, bins=100)\n",
    "axs[0].set_title('$K_m$');\n",
    "axs[0].set_ylim(0, 10)\n",
    "axs[1].hist(vmaxs, bins=100)\n",
    "axs[1].set_title('$V_{max}$');\n",
    "axs[1].set_ylim(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ba84b-b43a-473f-9be6-f485926482ee",
   "metadata": {},
   "source": [
    "The rather messy code below removes bootstrap samples outside the 5% highest and lowest values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c8119-0830-4920-aab4-c8c9a011ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_kms = sorted(kms)\n",
    "five_percent_sorted_kms = int((len(sorted_kms)/20))  # 5% = 1/20\n",
    "sorted_kms_min = sorted_kms[five_percent_sorted_kms]\n",
    "sorted_kms_max = sorted_kms[-five_percent_sorted_kms]\n",
    "\n",
    "sorted_vmaxs = sorted(vmaxs)\n",
    "five_percent_sorted_vmaxs = int((len(sorted_vmaxs)/20))  # 5% = 1/20\n",
    "sorted_vmaxs_min = sorted_vmaxs[five_percent_sorted_vmaxs]\n",
    "sorted_vmaxs_max = sorted_vmaxs[-five_percent_sorted_vmaxs]\n",
    "\n",
    "truncated_fits = []\n",
    "for bootstrap_fit in bootstrap_fits_100:\n",
    "    if sorted_kms_min < bootstrap_fit[0] < sorted_kms_max:\n",
    "        if sorted_vmaxs_min < bootstrap_fit[1] < sorted_vmaxs_max:\n",
    "            truncated_fits.append(bootstrap_fit)\n",
    "            \n",
    "truncated_kms, truncated_vmaxs = [], []\n",
    "for bootstrap_fit in truncated_fits:\n",
    "    truncated_kms.append(bootstrap_fit[0])\n",
    "    truncated_vmaxs.append(bootstrap_fit[1])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "axs[0].hist(truncated_kms, bins=100)\n",
    "axs[0].set_title('$K_m$');\n",
    "axs[1].hist(truncated_vmaxs, bins=100)\n",
    "axs[1].set_title('$v_{max}$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c00fbe-1681-4772-9565-0430b975a234",
   "metadata": {},
   "source": [
    "And finally, we *look at our data!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e8902-26ac-4a12-83e4-6aa0f995fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(truncated_kms, truncated_vmaxs, alpha=0.2)\n",
    "plt.xlabel('$K_m$')\n",
    "plt.ylabel('$V_{max}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39329f0a-cda4-412e-98c5-e77052be147c",
   "metadata": {},
   "source": [
    "... That's interesting.  There seems to be a correlation between the two values.  Let's do lots more bootstrap samples and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e7988-e10a-430d-bf6c-7c4bd7980be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_fits_10000 = []\n",
    "for _ in range(10000):\n",
    "    bootstrap_fits_10000.append(one_bootstrap_fit(mm_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b243f5d7-916f-4ef2-ae45-c3a2bf1f6cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kms, vmaxs = [], []\n",
    "for bootstrap_fit in bootstrap_fits_10000:\n",
    "    kms.append(bootstrap_fit[0])\n",
    "    vmaxs.append(bootstrap_fit[1])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "axs[0].hist(kms, bins=100)\n",
    "axs[0].set_title('$K_m$');\n",
    "axs[1].hist(vmaxs, bins=100)\n",
    "axs[1].set_title('$V_{max}$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16a639-75a8-45f5-8fdf-604ca3bac731",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_kms = sorted(kms)\n",
    "five_percent_sorted_kms = int((len(sorted_kms)/20))  # 5% = 1/20\n",
    "sorted_kms_min = sorted_kms[five_percent_sorted_kms]\n",
    "sorted_kms_max = sorted_kms[-five_percent_sorted_kms]\n",
    "\n",
    "sorted_vmaxs = sorted(vmaxs)\n",
    "five_percent_sorted_vmaxs = int((len(sorted_vmaxs)/20))  # 5% = 1/20\n",
    "sorted_vmaxs_min = sorted_vmaxs[five_percent_sorted_vmaxs]\n",
    "sorted_vmaxs_max = sorted_vmaxs[-five_percent_sorted_vmaxs]\n",
    "\n",
    "truncated_fits = []\n",
    "for bootstrap_fit in bootstrap_fits_10000:\n",
    "    if sorted_kms_min < bootstrap_fit[0] < sorted_kms_max:\n",
    "        if sorted_vmaxs_min < bootstrap_fit[1] < sorted_vmaxs_max:\n",
    "            truncated_fits.append(bootstrap_fit)\n",
    "            \n",
    "truncated_kms, truncated_vmaxs = [], []\n",
    "for bootstrap_fit in truncated_fits:\n",
    "    truncated_kms.append(bootstrap_fit[0])\n",
    "    truncated_vmaxs.append(bootstrap_fit[1])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "axs[0].hist(truncated_kms, bins=100)\n",
    "axs[0].set_title('$K_m$');\n",
    "axs[1].hist(truncated_vmaxs, bins=100)\n",
    "axs[1].set_title('$v_{max}$')\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(truncated_kms, truncated_vmaxs, alpha=0.01)\n",
    "plt.xlabel('$K_m$')\n",
    "plt.ylabel('$V_{max}$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe98e6-a7cf-4b32-adc5-518ca90bc982",
   "metadata": {},
   "source": [
    "Ok, so now we can see very clearly that there's a correlation across our samples.  What happens if we do replicates of our experiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9fc061-5c38-470e-9d06-0533f71f578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_rep1 = michaelis_menten(SUBSTRATE_CONCENTRATIONS, MM_KM, MM_VMAX)\n",
    "mm_rep2 = michaelis_menten(SUBSTRATE_CONCENTRATIONS, MM_KM, MM_VMAX)\n",
    "mm_rep3 = michaelis_menten(SUBSTRATE_CONCENTRATIONS, MM_KM, MM_VMAX)\n",
    "\n",
    "mm_rep1_noisy = make_noisy(mm_rep1)\n",
    "mm_rep2_noisy = make_noisy(mm_rep2)\n",
    "mm_rep3_noisy = make_noisy(mm_rep3)\n",
    "\n",
    "mm_s_rep = SUBSTRATE_CONCENTRATIONS*3  # Multiply a normal list gives three copies of list\n",
    "mm_v_rep = list(mm_rep1) + list(mm_rep2) + list(mm_rep3)  # Add a normal list add entries\n",
    "mm_v_rep_noisy = list(mm_rep1_noisy) + list(mm_rep2_noisy) + list(mm_rep3_noisy)  # Add a normal list add entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7e8426-846b-4d28-93b7-e3356dcc490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_data_rep = pd.DataFrame({'[s]': mm_s_rep,\n",
    "                            'v':   mm_v_rep,\n",
    "                            'v_noisy': mm_v_rep_noisy}\n",
    "                          )\n",
    "mm_data_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6657d2b7-2388-42a7-b3d8-27f49109eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_fitted, mm_covariance = curve_fit(f=michaelis_menten,\n",
    "                                     xdata=mm_data_rep['[s]'],\n",
    "                                     ydata=mm_data_rep['v_noisy'],\n",
    "                                     bounds=(0, np.inf)  # Force both Km and Vmax to be positive\n",
    "                                    )\n",
    "print('The theoretical K_m and V_max are: ', MM_KM, MM_VMAX)\n",
    "print('With my noisy data, the K_m and V_max are:', mm_fitted)\n",
    "\n",
    "plt.plot(SMOOTH_X,\n",
    "         michaelis_menten(SMOOTH_X, MM_KM, MM_VMAX),\n",
    "         label='Ground Truth')\n",
    "plt.plot(SMOOTH_X,\n",
    "         michaelis_menten(SMOOTH_X, mm_fitted[0], mm_fitted[1]),\n",
    "         label='Fitted')\n",
    "plt.scatter(mm_data_rep['[s]'],mm_data_rep['v_noisy'], label='with noise', color='orange', alpha=0.3)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa515ec-e082-451e-9371-2f1c48473f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_fits_rep_100 = []\n",
    "for _ in range(100):\n",
    "    bootstrap_fits_rep_100.append(one_bootstrap_fit(mm_data_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced6b5b-4a06-45bb-a988-881f3a5b7474",
   "metadata": {},
   "outputs": [],
   "source": [
    "kms, vmaxs = [], []\n",
    "for bootstrap_fit in bootstrap_fits_rep_100:\n",
    "    kms.append(bootstrap_fit[0])\n",
    "    vmaxs.append(bootstrap_fit[1])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "axs[0].hist(kms, bins=100)\n",
    "axs[0].set_title('$K_m$');\n",
    "axs[1].hist(vmaxs, bins=100)\n",
    "axs[1].set_title('$V_{max}$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5bead7-dc24-4082-9685-c65e48f58849",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "axs[0].hist(kms, bins=100)\n",
    "axs[0].set_title('$K_m$');\n",
    "axs[0].set_ylim(0,10)\n",
    "axs[1].hist(vmaxs, bins=100)\n",
    "axs[1].set_title('$V_{max}$');\n",
    "axs[1].set_ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7e42a-7913-466e-b65b-dbc8f605b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_kms = sorted(kms)\n",
    "five_percent_sorted_kms = int((len(sorted_kms)/20))  # 5% = 1/20\n",
    "sorted_kms_min = sorted_kms[five_percent_sorted_kms]\n",
    "sorted_kms_max = sorted_kms[-five_percent_sorted_kms]\n",
    "\n",
    "sorted_vmaxs = sorted(vmaxs)\n",
    "five_percent_sorted_vmaxs = int((len(sorted_vmaxs)/20))  # 5% = 1/20\n",
    "sorted_vmaxs_min = sorted_vmaxs[five_percent_sorted_vmaxs]\n",
    "sorted_vmaxs_max = sorted_vmaxs[-five_percent_sorted_vmaxs]\n",
    "\n",
    "truncated_fits = []\n",
    "for bootstrap_fit in bootstrap_fits_rep_100:\n",
    "    if sorted_kms_min < bootstrap_fit[0] < sorted_kms_max:\n",
    "        if sorted_vmaxs_min < bootstrap_fit[1] < sorted_vmaxs_max:\n",
    "            truncated_fits.append(bootstrap_fit)\n",
    "            \n",
    "truncated_kms, truncated_vmaxs = [], []\n",
    "for bootstrap_fit in truncated_fits:\n",
    "    truncated_kms.append(bootstrap_fit[0])\n",
    "    truncated_vmaxs.append(bootstrap_fit[1])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "axs[0].hist(truncated_kms, bins=100)\n",
    "axs[0].set_title('$K_m$');\n",
    "axs[1].hist(truncated_vmaxs, bins=100)\n",
    "axs[1].set_title('$v_{max}$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d72254-1564-4eb3-b26d-05197ae94436",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_fits_rep_10000 = []\n",
    "for _ in range(10000):\n",
    "    bootstrap_fits_rep_10000.append(one_bootstrap_fit(mm_data_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d217a-d315-4064-9a8f-0614b3799da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kms, vmaxs = [], []\n",
    "for bootstrap_fit in bootstrap_fits_rep_10000:\n",
    "    kms.append(bootstrap_fit[0])\n",
    "    vmaxs.append(bootstrap_fit[1])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "axs[0].hist(kms, bins=100)\n",
    "axs[0].set_title('$K_m$');\n",
    "axs[1].hist(vmaxs, bins=100)\n",
    "axs[1].set_title('$V_{max}$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcb6396-5a9d-4697-a477-5eed294fa33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "axs[0].hist(kms, bins=100)\n",
    "axs[0].set_title('$K_m$');\n",
    "axs[0].set_ylim(0,10)\n",
    "axs[1].hist(vmaxs, bins=100)\n",
    "axs[1].set_title('$V_{max}$');\n",
    "axs[1].set_ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855df99e-8075-4f43-ba2f-06c6ec222be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_kms = sorted(kms)\n",
    "five_percent_sorted_kms = int((len(sorted_kms)/20))  # 5% = 1/20\n",
    "sorted_kms_min = sorted_kms[five_percent_sorted_kms]\n",
    "sorted_kms_max = sorted_kms[-five_percent_sorted_kms]\n",
    "\n",
    "sorted_vmaxs = sorted(vmaxs)\n",
    "five_percent_sorted_vmaxs = int((len(sorted_vmaxs)/20))  # 5% = 1/20\n",
    "sorted_vmaxs_min = sorted_vmaxs[five_percent_sorted_vmaxs]\n",
    "sorted_vmaxs_max = sorted_vmaxs[-five_percent_sorted_vmaxs]\n",
    "\n",
    "truncated_fits = []\n",
    "for bootstrap_fit in bootstrap_fits_rep_10000:\n",
    "    if sorted_kms_min < bootstrap_fit[0] < sorted_kms_max:\n",
    "        if sorted_vmaxs_min < bootstrap_fit[1] < sorted_vmaxs_max:\n",
    "            truncated_fits.append(bootstrap_fit)\n",
    "            \n",
    "truncated_kms, truncated_vmaxs = [], []\n",
    "for bootstrap_fit in truncated_fits:\n",
    "    truncated_kms.append(bootstrap_fit[0])\n",
    "    truncated_vmaxs.append(bootstrap_fit[1])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "axs[0].hist(truncated_kms, bins=100)\n",
    "axs[0].set_title('$K_m$');\n",
    "axs[1].hist(truncated_vmaxs, bins=100)\n",
    "axs[1].set_title('$v_{max}$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626bd532-575d-49db-879a-f0485dd28d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(truncated_kms, truncated_vmaxs, alpha=0.05)\n",
    "plt.xlabel('$K_m$')\n",
    "plt.ylabel('$V_{max}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a5457-7e8c-4f11-b298-afc164dee613",
   "metadata": {},
   "source": [
    "Ok, so now we can see the true distribution of our errors.  Note that they're correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade7872-7d1e-44a0-9e69-6fed03460a6a",
   "metadata": {},
   "source": [
    "# Model selection\n",
    "The first, simplest way to see if you model is any good, is to simply plot the residuals: subtract your predicted values from your measured values, and look at the results.\n",
    "\n",
    "## plotting residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c7fd5c-54a6-453c-afa5-70de2cd46a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_fitted, mm_covariance = curve_fit(f=michaelis_menten,\n",
    "                                     xdata=mm_data_rep['[s]'],\n",
    "                                     ydata=mm_data_rep['v_noisy'],\n",
    "                                     bounds=(0, np.inf)  # Force both Km and Vmax to be positive\n",
    "                                    )\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "\n",
    "axs[0].plot(SMOOTH_X, michaelis_menten(SMOOTH_X, mm_fitted[0], mm_fitted[1]), label='Fitted')\n",
    "axs[0].scatter(mm_data_rep['[s]'], mm_data_rep['v_noisy'], color='orange', alpha=0.5)\n",
    "axs[0].set_title('Fit')\n",
    "y_range = axs[0].get_ylim()[1] - axs[0].get_ylim()[0]\n",
    "\n",
    "fit_values = michaelis_menten(mm_data_rep['[s]'], mm_fitted[0], mm_fitted[1])\n",
    "subtracted_values = mm_data_rep['v_noisy'] - fit_values\n",
    "axs[1].scatter(mm_data_rep['[s]'], subtracted_values)\n",
    "axs[1].set_title('Data - Fit')\n",
    "axs[1].set_ylim(-y_range/2, y_range/2)\n",
    "axs[1].hlines(0, mm_data_rep['[s]'].min(), mm_data_rep['[s]'].max(), linestyles='dashed');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df19c5-ff6f-44a9-9010-810a6fcc4321",
   "metadata": {},
   "source": [
    "Do you see any 'structure' in the data?  If it looks randomly-distributed, then you *may* have a good model.\n",
    "\n",
    "# Cross Validation\n",
    "Start with some convenience functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e522433a-3533-405f-8908-00ac559414f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fold_ids(folds, length):\n",
    "    fold_id = np.arange(0, length)\n",
    "    fold_id = fold_id % folds\n",
    "    rng = np.random.default_rng()\n",
    "    rng.shuffle(fold_id)\n",
    "    return fold_id\n",
    "\n",
    "def cross_val_error_comparison(df, f1, f2, folds=10):\n",
    "    cross_validation_error1, cross_validation_error2 = 0, 0\n",
    "    df = df.copy(deep=True)\n",
    "    df['__fold id__'] = make_fold_ids(folds, len(df))\n",
    "    for fold_id in sorted(df['__fold id__'].unique()):\n",
    "        df_validate = df[df['__fold id__'] == fold_id]\n",
    "        df_train = df[df['__fold id__'] != fold_id]\n",
    "\n",
    "        fitted1, covariance1 = curve_fit(f=f1,\n",
    "                                         xdata=df_train['[s]'],\n",
    "                                         ydata=df_train['v_noisy'],\n",
    "                                         max_nfev=10000,\n",
    "                                         bounds=(0, np.inf)  # Force both Km and Vmax to be positive\n",
    "                                        )\n",
    "        fitted_predictions1 = f1(df_validate['[s]'], *fitted1)\n",
    "        cross_validation_error1 += sum((df_validate['v_noisy'] - fitted_predictions1)**2)\n",
    "        \n",
    "        fitted2, covariance2 = curve_fit(f=f2,\n",
    "                                         xdata=df_train['[s]'],\n",
    "                                         ydata=df_train['v_noisy'],\n",
    "                                         max_nfev=10000,\n",
    "                                         bounds=(0, np.inf)  # Force both Km and Vmax to be positive\n",
    "                                        )\n",
    "        fitted_predictions2 = f2(df_validate['[s]'], *fitted2)\n",
    "        cross_validation_error2 += sum((df_validate['v_noisy'] - fitted_predictions2)**2)               \n",
    "        \n",
    "    return cross_validation_error1, cross_validation_error2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f016a-b0d4-4665-aada-f3aea88fd8aa",
   "metadata": {},
   "source": [
    "For completeness, we fake some data from the augmented MM equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e24f5d-46f2-4e57-b8ea-c6071fb0f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MM_KD1 = 0.2\n",
    "MM_KD2 = 0.4\n",
    "MM_ALPHA = 0.9\n",
    "MM_BETA = 0.1\n",
    "\n",
    "mm_ha_rep1 = michaelis_menten_ha(SUBSTRATE_CONCENTRATIONS, MM_KD1, MM_KD1, MM_ALPHA, MM_BETA, MM_VMAX)\n",
    "mm_ha_rep2 = michaelis_menten_ha(SUBSTRATE_CONCENTRATIONS, MM_KD1, MM_KD1, MM_ALPHA, MM_BETA, MM_VMAX)\n",
    "mm_ha_rep3 = michaelis_menten_ha(SUBSTRATE_CONCENTRATIONS, MM_KD1, MM_KD1, MM_ALPHA, MM_BETA, MM_VMAX)\n",
    "\n",
    "mm_ha_rep1_noisy = make_noisy(mm_ha_rep1)\n",
    "mm_ha_rep2_noisy = make_noisy(mm_ha_rep2)\n",
    "mm_ha_rep3_noisy = make_noisy(mm_ha_rep3)\n",
    "\n",
    "mm_ha_s_rep = SUBSTRATE_CONCENTRATIONS*3  # Multiply a normal list gives three copies of list\n",
    "mm_ha_v_rep = list(mm_ha_rep1) + list(mm_ha_rep2) + list(mm_ha_rep3)  # Add a normal list add entries\n",
    "mm_ha_v_rep_noisy = list(mm_ha_rep1_noisy) + list(mm_ha_rep2_noisy) + list(mm_ha_rep3_noisy)  # Add a normal list add entries\n",
    "\n",
    "mm_ha_data_rep = pd.DataFrame({'[s]': mm_ha_s_rep,\n",
    "                            'v':   mm_ha_v_rep,\n",
    "                            'v_noisy': mm_ha_v_rep_noisy}\n",
    "                          )\n",
    "mm_ha_data_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d9c5af-3cad-4c77-b0d8-4d2c65b9e507",
   "metadata": {},
   "source": [
    "... And now we see how the fitting does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cbe44e-45fa-4ee7-a9c2-43c9acf10d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_fitted, mm_covariance = curve_fit(f=michaelis_menten,\n",
    "                                     xdata=mm_ha_data_rep['[s]'],\n",
    "                                     ydata=mm_ha_data_rep['v_noisy'],\n",
    "                                     bounds=(0, np.inf)  # Force both Km and Vmax to be positive\n",
    "                                    )\n",
    "mm_ha_fitted, mm_ha_covariance = curve_fit(f=michaelis_menten_ha,\n",
    "                                     xdata=mm_ha_data_rep['[s]'],\n",
    "                                     ydata=mm_ha_data_rep['v_noisy'],\n",
    "                                     # p0=[1,1,1,1,1],\n",
    "                                     bounds=(0, np.inf)  # Force both Km and Vmax to be positive\n",
    "                                    )\n",
    "print('With a standard Michaelis-Menten, the fitted K_m and V_max are:', mm_fitted)\n",
    "print('With a Homotropic Allosterism Michaelis-Menten, the fitted K_d1, K_d2, alpha and V_max are:', mm_ha_fitted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31316a80-3229-4af3-82a1-c4c5578d223a",
   "metadata": {},
   "source": [
    "*ALWAYS LOOK AT YOUR DATA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d20aae-d2bc-4baa-a2a6-f6abd5916d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fits and residuals\n",
    "fig, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "\n",
    "axs[0].plot(SMOOTH_X, michaelis_menten(SMOOTH_X, mm_fitted[0], mm_fitted[1]), label='MM')\n",
    "axs[0].plot(SMOOTH_X, michaelis_menten_ha(SMOOTH_X, mm_ha_fitted[0], mm_ha_fitted[1], mm_ha_fitted[2], mm_ha_fitted[3], mm_ha_fitted[4]), label='MM HA')\n",
    "\n",
    "axs[0].scatter(mm_ha_data_rep['[s]'], mm_ha_data_rep['v_noisy'], color='orange', alpha=0.5)\n",
    "axs[0].set_title('Fit')\n",
    "y_range = axs[0].get_ylim()[1] - axs[0].get_ylim()[0]\n",
    "\n",
    "fit_values_mm = michaelis_menten(mm_ha_data_rep['[s]'], mm_fitted[0], mm_fitted[1])\n",
    "subtracted_values_mm = mm_ha_data_rep['v_noisy'] - fit_values_mm\n",
    "axs[1].scatter(mm_ha_data_rep['[s]'], subtracted_values_mm)\n",
    "axs[1].set_title('Data - Fit (MM)')\n",
    "axs[1].set_ylim(-y_range/2, y_range/2)\n",
    "axs[1].hlines(0, mm_ha_data_rep['[s]'].min(), mm_ha_data_rep['[s]'].max(), linestyles='dashed')\n",
    "\n",
    "fit_values_mm_ha = michaelis_menten_ha(mm_ha_data_rep['[s]'], mm_ha_fitted[0], mm_ha_fitted[1], mm_ha_fitted[2], mm_ha_fitted[3], mm_ha_fitted[4])\n",
    "subtracted_values_mm_ha = mm_ha_data_rep['v_noisy'] - fit_values_mm_ha\n",
    "axs[2].scatter(mm_ha_data_rep['[s]'], subtracted_values_mm_ha)\n",
    "axs[2].set_title('Data - Fit (MM-HA)')\n",
    "axs[2].set_ylim(-y_range/2, y_range/2)\n",
    "axs[2].hlines(0, mm_ha_data_rep['[s]'].min(), mm_ha_data_rep['[s]'].max(), linestyles='dashed');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5484b-c355-43ab-93f7-fff4985b673a",
   "metadata": {},
   "source": [
    "Note that fitting MM-HA data with a standard MM equation gives a bit of strcture to your residuals.  MM-HA data fitted with the MM-HA equation looks more random.  \n",
    "\n",
    "Finally, we can compare the cross validation errors for the two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d411b9-db1a-49ce-97ac-d54e0584c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "xval_mm, xval_mm_ha = cross_val_error_comparison(mm_data_rep, michaelis_menten, michaelis_menten_ha, 5)\n",
    "print('The cross validation error for MM data with the sandard and HA equations are:',xval_mm, 'and', xval_mm_ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb4e8a7-41b8-4b8d-8477-67d25c89b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xval_ratio = xval_mm / xval_mm_ha\n",
    "\n",
    "if xval_ratio < 0.95:\n",
    "    print('Michaelis-Menton is the prefered model.')\n",
    "elif 1/xval_ratio < 0.95:\n",
    "    print('Michaelis-Menton with Homotropic Alostery is the prefered model.')\n",
    "else:\n",
    "    print(\"The cross validation scores are too close, we can't descriminiate between the models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f27d92b-292f-42ab-9f7e-d3acfcd8c134",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "Do the above cross validation analysis for the MM-HA data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15dd4e5-70de-4831-9b23-88fb6b1b5581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf8482e-14fc-4d2b-911d-2738e2adf74d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
